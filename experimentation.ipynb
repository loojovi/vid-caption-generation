{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRM0MM9v6x3c"
   },
   "source": [
    "## Set up directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-r_UyyBaIHD",
    "outputId": "b77e7ff9-9c0c-4b9b-aec2-dc10e770a374"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5jjEEeL9iyY",
    "outputId": "20915cbb-a869-40ce-8398-7acb983256c5"
   },
   "outputs": [],
   "source": [
    "%cd ./gdrive/MyDrive/deep_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmrDEisjVU3s"
   },
   "source": [
    "## Reading in batch image and feeding it into CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxKO2nTR3n8L"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torchtext.vocab import GloVe\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random \n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import os \n",
    "from utils import *\n",
    "\n",
    "# LOG: \n",
    "# model_chkpt - base model --> poor performance \n",
    "# model_chkpt_s2s - base model (encoder/decoder, dropout 0.2) --> poor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6LIip9DScNf"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHhnD4ziI4p7",
    "outputId": "6375f6d2-54e1-4955-df3b-2bbf3e304e38"
   },
   "outputs": [],
   "source": [
    "feature_extractor = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
    "feature_extractor = torch.nn.Sequential(*list(feature_extractor.children())[:-1]) # strip last layer\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "validation_size = 0.2\n",
    "max_epochs = 4\n",
    "\n",
    "# PARAMS (DATA LOAD)\n",
    "params = {'batch_size': 12,\n",
    "          'shuffle': True}\n",
    "\n",
    "# LOAD LABELS\n",
    "f = open('data/training_annotation.json')\n",
    "targets = json.load(f)\n",
    "f.close()\n",
    "\n",
    "image_ids = list(targets.keys())\n",
    "random.seed(10)\n",
    "random.shuffle(image_ids)\n",
    "\n",
    "# Split data into validation and train set\n",
    "partition = {\n",
    "    'validation': image_ids[:int(validation_size*len(image_ids))],\n",
    "    'train': image_ids[int(validation_size*len(image_ids)):]\n",
    "}\n",
    "\n",
    "# Initiliaze video frame transformer\n",
    "train_transformer =  transforms.Compose([transforms.Resize((224,224)), \n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "training_set = FrameDataset(partition['train'], targets, train_transformer, feature_extractor)\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = FrameDataset(partition['validation'], targets, train_transformer, feature_extractor)\n",
    "validation_generator = DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvsqsiKnMq0D"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "loss = criterion(pred1, labels[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbTJltIeOjTQ",
    "outputId": "031a2893-8224-44ec-e00e-4214cc8ba412"
   },
   "outputs": [],
   "source": [
    "feature_extractor = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
    "feature_extractor = torch.nn.Sequential(*list(feature_extractor.children())[:-1]) # strip last layer\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "validation_size = 0.2\n",
    "max_epochs = 4\n",
    "\n",
    "# PARAMS (DATA LOAD)\n",
    "params = {'batch_size': 12,\n",
    "          'shuffle': True}\n",
    "\n",
    "# LOAD LABELS\n",
    "f = open('data/training_annotation.json')\n",
    "targets = json.load(f)\n",
    "f.close()\n",
    "\n",
    "image_ids = list(targets.keys())\n",
    "random.seed(10)\n",
    "random.shuffle(image_ids)\n",
    "\n",
    "partition = {\n",
    "    'validation': image_ids[:int(validation_size*len(image_ids))],\n",
    "    'train': image_ids[int(validation_size*len(image_ids)):]\n",
    "}\n",
    "\n",
    "train_transformer =  transforms.Compose([transforms.Resize((224,224)), \n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "training_set = FrameDataset(partition['train'], targets, train_transformer, feature_extractor)\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = FrameDataset(partition['validation'], targets, train_transformer, feature_extractor)\n",
    "validation_generator = DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "model = Seq2Seq() # change type of model to experiment different ones \n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "start_epoch = 0 \n",
    "valid_loss_min = np.Inf\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "train_loss_it = []\n",
    "\n",
    "\n",
    "checkpoint_path = './model/current_checkpoint_ori_adam.pt'\n",
    "best_model_path = './model/best_model_ori_adam.pt'\n",
    "\n",
    "# load the saved checkpoint (uncomment line below if loading previously saved model)\n",
    "model, optimizer, start_epoch, valid_loss_min, train_loss_list, valid_loss_list, train_loss_it = load_ckp(checkpoint_path, model, optimizer)\n",
    "start_params = model.named_parameters() # save initial state of model to check if model parameters are updated at all \n",
    "\n",
    "for epoch in range(start_epoch, max_epochs):\n",
    "    print(f'---------- Starting epoch {epoch} ----------')\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch_idx, (batch_data, labels) in enumerate(training_generator):\n",
    "        batch_size = batch_data.shape[0]\n",
    "        # Transfer to GPU\n",
    "        batch_data, labels = batch_data.to(device), [label.to(device) for label in labels]\n",
    "        object1_pred, relationship_pred, object2_pred = model(batch_data)\n",
    "        loss = criterion(object1_pred, labels[0]) + criterion(relationship_pred, labels[1]) + criterion(object2_pred, labels[2])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5 == 0:\n",
    "            av_loss = loss/batch_size\n",
    "            print(f'Iteration {batch_idx} completed with avg loss {av_loss}')\n",
    "        train_loss_it.append(av_loss)\n",
    "        train_loss = train_loss + loss\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        val_loss = []\n",
    "        for batch_idx, (batch_data, labels) in enumerate(validation_generator):\n",
    "             batch_data, labels = batch_data.to(device), [label.to(device) for label in labels]\n",
    "             object1_pred, relationship_pred, object2_pred = model(batch_data)\n",
    "             loss = criterion(object1_pred, labels[0]) + criterion(relationship_pred, labels[1]) + criterion(object2_pred, labels[2])\n",
    "             if batch_idx % 5 == 0:\n",
    "                print(f'Validation iteration {batch_idx} completed')\n",
    "             valid_loss = valid_loss + loss\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(partition['train'])\n",
    "    valid_loss = valid_loss/len(partition['validation'])\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # create checkpoint variable and add important data\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'valid_loss_min': valid_loss,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'train_loss_list': train_loss_list,\n",
    "        'valid_loss_list': valid_loss_list,\n",
    "        'train_loss_it': train_loss_it\n",
    "    }\n",
    "    \n",
    "    # save checkpoint\n",
    "    save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "    \n",
    "    ## save the model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "        # save checkpoint as best model\n",
    "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "OwtrzC43sBjy",
    "outputId": "9c477ef8-e93f-42f5-e46e-8c7130395dce"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# visualize training loss over time - huge fluctuations, but generally the loss went down\n",
    "plt.plot(train_loss_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4NiYxusJLA8"
   },
   "source": [
    "Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rO-StkinJODn"
   },
   "outputs": [],
   "source": [
    "best_model_path = './model/best_model_s2s.pt'\n",
    "model, optimizer, start_epoch, valid_loss_min, train_loss_list, valid_loss_list, train_loss_it = load_ckp(best_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzBiVA-mU8e2",
    "outputId": "1d5f8979-f28d-4ae2-8208-368595cd42a3"
   },
   "outputs": [],
   "source": [
    "feature_extractor = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
    "feature_extractor = torch.nn.Sequential(*list(feature_extractor.children())[:-1]) # strip last layer\n",
    "test_data_dir = 'data/test/test/'\n",
    "test_ids = os.listdir(test_data_dir)\n",
    "test_transformer =  transforms.Compose([transforms.Resize((224,224)), \n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "label = []\n",
    "model.eval()\n",
    "for ID in test_ids:\n",
    "    path2frames = glob.glob(test_data_dir + ID + '/*.jpg')\n",
    "    path2frames.sort() \n",
    "    path2frames = path2frames[1::3]\n",
    "    test_images = extract_test_images(test_transformer, feature_extractor, path2frames)\n",
    "    test_images = test_images.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        object1_pred, relationship_pred, object2_pred = model(test_images)\n",
    "    te = (torch.topk(object1_pred,5)[1].squeeze().cpu()).numpy()\n",
    "    label.append(' '.join(map(str, te)))\n",
    "    te = (torch.topk(relationship_pred,5)[1].squeeze().cpu()).numpy()\n",
    "    label.append(' '.join(map(str, te)))\n",
    "    te = (torch.topk(object2_pred,5)[1].squeeze().cpu()).numpy()\n",
    "    label.append(' '.join(map(str, te)))\n",
    "\n",
    "ID_list = [i for i in range(len(label))]\n",
    "df = pd.DataFrame(list(zip(ID_list, label)),\n",
    "               columns =['ID', 'label'])\n",
    "df.to_csv('predictions_02042021.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "experimentation_jovi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
